# HMM Sequence Alignment
This project was done as a part of the Bioinformatics 2 course at the Faculty of Electrical Engineering and Computing. The goal was to implement a pairwise nucleotide sequence alignment model based on hidden Markov model theory. 

## Project Overview
### Nucleotide Sequence Alignment
Nucleotide sequences (DNA and RNA) consist of a large number of nucleotides. There are four nucleotides that can appear in a DNA sequence, whose symbols are A, C, T, and G. In RNA sequences, nucleotide T is replaced with nucleotide U. Nucleotide sequences in bioinformatics can therefore be viewed as large strings, for example:

ATGAAAGTGAAGGAGATCATGAAGAATTATCGGCACTTATGGAA...

To compare two (or more) protein sequences (e.g., to determine regions of similarity, predict functional and structural similarities, or determine an evolutionary relationship), they need to be aligned. Aligning two or more sequences means inserting gap characters (gap character is "-") at appropriate positions in the sequences to achieve as many matches as possible. There are many computational algorithms based on dynamic programming that have been applied to the sequence alignment problem. These algorithms produce optimal alignments but suffer from large time and space complexities when dealing with longer sequences. The algorithm implemented in this project uses probabilities and hidden Markov model theory to produce alignments.

### Hidden Markov Models
Hidden Markov models include states and observations that are emitted in those states. The parameters of such a model are matrix π, which represents probabilities for starting from each state; matrix A, which represents probabilities for state transition; and matrix E, which represents probabilities that a certain symbol will be emitted in a certain state. In the case of a pairwise sequence alignment, possible states are match and insertion in the first (second sequence contains a gap) or the second sequence (first sequence contains a gap), while symbols that can be emitted are nucleotide pairs (columns of an alignment). In a match state, there are 16 pairs of nucleotides in total that can be emitted. In the case of an insertion state, there are four possible symbols that can be emitted (4 nucleotides with a gap in the first/second position). The picture below shows a hidden Markov model for pairwise nucleotide sequence alignment:

![image](https://github.com/ivanfurac/HMM-Sequence-Alignment/assets/73389887/778e1e01-20fd-4bdf-bdeb-b415d659eabd)

### Project Structure
There are four steps in training an HMM model for sequence alignment and checking its performance:
* **data preprocessing**: The HIV sequences dataset that was used in this project can be downloaded from the [NCBI website](https://www.hiv.lanl.gov/content/sequence/NEWALIGN/align.html), and it can also be found in the repository.
* **model training**: Initial parameter values (matrixes π, A, and E) are calculated based on training data. Parameters are then updated using the Baum-Welch algorithm, in multiple iterations (here values converged after 5 iterations).
* **sequence aligning**: After optimal model parameters are found, two sequences can be aligned using the Viterbi algorithm. This algorithm finds the most probable series of hidden states that correspond with input sequences. The alignment is then generated by emitting pairs of nucleotides from the sequences (or a nucleotide and a gap) based on those hidden states.
* **model scoring**: Reference alignments are generated using the Needleman-Wunsch algorithm. The alignments produced by the HMM model are compared with the reference alignments using a scoring system that includes penalties for gap opening and gap extension and rewards for nucleotide matches. Scores are calculated independently for both methods and for each alignment, and a mean squared error is calculated at the end.

### Results and Future Work 
The scores for the HMM model are on average 30% lower than the scores of reference alignments. The aligning process itself is quite fast, but the generated alignments are mostly suboptimal. A solution to this problem could be the use of a larger dataset (80 pairs of sequences are used in this project), but in this case the training process would last much longer and larger computational resources would be needed.

## Repository and Usage

## Authors and Acknowledgment
The coauthor on this project was my colleague Jana Martinović (https://github.com/janamarti).
